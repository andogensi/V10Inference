# V10Inference

V10Inference ã¯ã€ONNXå½¢å¼ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸé«˜é€Ÿæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚CUDAå¯¾å¿œã®GPUã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚Šã€åŠ¹ç‡çš„ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¨è«–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

## ç‰¹å¾´

- ğŸš€ **CUDA ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: GPU ã‚’æ´»ç”¨ã—ãŸé«˜é€Ÿæ¨è«–
- ğŸ“¦ **ONNX ã‚µãƒãƒ¼ãƒˆ**: æ¨™æº–çš„ãªONNXå½¢å¼ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œ
- ğŸ¯ **ç”»åƒåˆ†é¡**: MNIST ãªã©ã®ç”»åƒèªè­˜ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œ
- ğŸ”§ **ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼è¨­è¨ˆ**: æ‹¡å¼µã—ã‚„ã™ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

## ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
V10Inference/
â”œâ”€â”€ include/               # å…¬é–‹ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ inference_engine.h
â”‚   â”œâ”€â”€ image_loader.h
â”‚   â””â”€â”€ model_loader.h
â”œâ”€â”€ src/                   # å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ core/             # ã‚³ã‚¢æ©Ÿèƒ½
â”‚   â”‚   â””â”€â”€ inference_engine.cpp
â”‚   â”œâ”€â”€ loaders/          # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
â”‚   â”‚   â”œâ”€â”€ image_loader.cpp
â”‚   â”‚   â””â”€â”€ model_loader.cpp
â”‚   â””â”€â”€ cuda/             # CUDAã‚«ãƒ¼ãƒãƒ«
â”‚       â””â”€â”€ kernels.cu
â”œâ”€â”€ third_party/          # ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
â”‚   â””â”€â”€ onnx/
â”‚       â”œâ”€â”€ onnx.pb.h
â”‚       â””â”€â”€ onnx.pb.cc
â””â”€â”€ examples/             # ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰
    â””â”€â”€ main.cpp
```

## å¿…è¦è¦ä»¶

### ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢
- Visual Studio 2022 (ã¾ãŸã¯ãã‚Œä»¥é™)
- CUDA Toolkit 13.0 (ã¾ãŸã¯ãã‚Œä»¥é™)
- C++17 å¯¾å¿œã‚³ãƒ³ãƒ‘ã‚¤ãƒ©

### ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢
- CUDAå¯¾å¿œ NVIDIA GPU

## ãƒ“ãƒ«ãƒ‰æ–¹æ³•

### Visual Studio ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ

1. `V10Inference.sln` ã‚’ Visual Studio ã§é–‹ã
2. ãƒ“ãƒ«ãƒ‰æ§‹æˆã‚’é¸æŠ (Debug ã¾ãŸã¯ Release)
3. ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’ x64 ã«è¨­å®š
4. ãƒ“ãƒ«ãƒ‰ â†’ ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ“ãƒ«ãƒ‰

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```bash
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å®Ÿè¡Œ
V10Inference.exe

# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š
V10Inference.exe -i my_digit.png

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸¡æ–¹ã‚’æŒ‡å®š
V10Inference.exe -i my_digit.png -m mnist-8.onnx
```

### ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ ã‚ªãƒ—ã‚·ãƒ§ãƒ³

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ |
|-----------|------|-------------|
| `-i, --image <path>` | å…¥åŠ›ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ | `test_digit.png` |
| `-m, --model <path>` | ONNXãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ | `mnist-8.onnx` |
| `-h, --help` | ãƒ˜ãƒ«ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º | - |

### ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã®ä½¿ç”¨ä¾‹

```cpp
#include "model_loader.h"
#include "image_loader.h"
#include "inference_engine.h"

int main() {
    // ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    ModelLoader model;
    model.loadModel("mnist-8.onnx");
    
    // ç”»åƒã®èª­ã¿è¾¼ã¿
    ImageLoader imgLoader;
    int width, height;
    auto image = imgLoader.loadMNISTImage("test.png", width, height);
    
    // æ¨è«–ã®å®Ÿè¡Œ
    InferenceEngine engine(model);
    int prediction = engine.run(image);
    
    std::cout << "äºˆæ¸¬çµæœ: " << prediction << std::endl;
    return 0;
}
```

## API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### ModelLoader

ONNXãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®ã‚¯ãƒ©ã‚¹ã€‚

```cpp
class ModelLoader {
public:
    bool loadModel(const std::string& model_path);
    std::vector<float> getTensorData(const std::string& tensor_name) const;
    void printModelInfo() const;
};
```

### ImageLoader

ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æ¨è«–ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚

```cpp
class ImageLoader {
public:
    std::vector<float> loadMNISTImage(const std::string& path, int& width, int& height);
    std::vector<float> createDefaultPattern();
};
```

### InferenceEngine

ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ã‚¸ãƒ³ã€‚

```cpp
class InferenceEngine {
public:
    InferenceEngine(const ModelLoader& model);
    int run(const std::vector<float>& input_image);
};
```

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±ã«ã¤ã„ã¦ã¯ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚ªãƒ¼ãƒŠãƒ¼ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚

## è²¢çŒ®

ãƒã‚°å ±å‘Šã‚„æ©Ÿèƒ½è¦æœ›ã¯ã€GitHubã®Issuesã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ãŠé¡˜ã„ã—ã¾ã™ã€‚

## ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:

1. CUDA ToolkitãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹
2. ä½¿ç”¨ã—ã¦ã„ã‚‹GPUãŒCUDAå¯¾å¿œã‹
3. Visual Studioã®ãƒ“ãƒ«ãƒ‰è¨­å®šãŒæ­£ã—ã„]

---

**Made with â¤ï¸ for High-Performance AI Inference**
